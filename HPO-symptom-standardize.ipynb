{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2ab8f5",
   "metadata": {},
   "source": [
    "# Standardizing Clinical Symptoms of Rare Disease with Human Phenotype Ontology (HPO) in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161724c2",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916fbda",
   "metadata": {},
   "source": [
    "In literature reviews and evidence synthesis for rare diseases, clinical symptoms are often reported in non-standardized ways, making it difficult to compare or merge them computationally.\n",
    "\n",
    "This real-world challenge motivated us to develop a data solution for standardizing free-text symptom reports. Using the open-source Human Phenotype Ontology (HPO) and its API, we can map reported symptoms to controlled ontology terms, with the process automated in Python.\n",
    "\n",
    "I streamlined the workflow into several steps: retrieving candidate HPO terms and synonyms, linking them to IDs and definitions, and applying fuzzy matching to identify similarities between reported symptoms and retrieved HPO terms. This notebook demonstrates the pipeline with minimal documentation as a reference for the community.\n",
    "\n",
    "The workflow has been tested in a real-world project on congenital myasthenic syndromes (CMS). While effective, there remain opportunities to refine and expand the approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418fc71",
   "metadata": {},
   "source": [
    "## Alogrithm explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbc8bc",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "Standardize free-text clinical symptoms by mapping them to HPO (Human Phenotype Ontology) terms, then verify and contextualize each match.\n",
    "\n",
    "**Inputs**: symptom (str): A reported, free-text symptom (e.g., “ptosis”, “muscle weakness”).\n",
    "\n",
    "**External resources & libs**\n",
    "- Search API: https://ontology.jax.org/api/hp/search/?q=<symptom> (top result taken)\n",
    "- Ontology file: http://purl.obolibrary.org/obo/hp.obo (definitions, synonyms, hierarchy)\n",
    "- Python libs: requests, fuzzywuzzy.process.extractOne, obonet, functools.lru_cache, pandas (optional)\n",
    "\n",
    "**High-level flow**\n",
    "1. Search HPO: Query the JAX HPO API with the input symptom → get top candidate (name, id) or no result.\n",
    "2.\tFuzzy validation: Compute a fuzzy score between the input symptom and the returned HPO term name.\n",
    "3.\tContext retrieval: From hp.obo, pull definition and synonyms for the candidate HPO ID.\n",
    "4.\tLineage extraction: From the same ontology graph, compute depth and path to root HP:0000001 (using first parent if multiple).\n",
    "5.\tAccept/Reject decision\n",
    "\t- Accept if fuzzy_score ≥ 80 OR HPO name appears in its synonyms (case-insensitive check).\n",
    "\t- Reject otherwise (or if API/ontology lookup fails).\n",
    "\n",
    "**Decision rule (acceptance)**\n",
    "- Threshold: fuzzy_score ≥ 80\n",
    "- Synonym override: Accept if HPO term name is present among its synonyms (case-insensitive)\n",
    "\n",
    "**Rationale**: Puts speed/recall first (top hit) with a sanity check on similarity; adds semantic cushion via synonyms.\n",
    "\n",
    "**Outputs (as implemented)**\n",
    "\n",
    "The pipeline returns 8 fields in fixed order:  \n",
    "1. reported_symptom (str) \n",
    "2.\thpo_term (str | None) \n",
    "3.\thpo_id (str | None)\n",
    "4.\tdefinition (str | None)\n",
    "5.\trank (int | None)\n",
    "6.\tpath (list[str] | [])\n",
    "7.\tfuzzy_score (int | 0)\n",
    "8.\tstatus (“matched” | “not matched”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb049ea",
   "metadata": {},
   "source": [
    "## Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14b75225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Iterable, Optional\n",
    "\n",
    "# Specific modules\n",
    "import rapidfuzz\n",
    "from fuzzywuzzy import process\n",
    "import obonet\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130fd4c",
   "metadata": {},
   "source": [
    "**Brief information for the specific modules**\n",
    "\n",
    "- `fuzzywuzzy.process`: Provides fuzzy string matching, useful for comparing free-text symptoms to HPO terms and synonyms.\n",
    "- `obonet`: Loads and parses OBO-formatted ontology files, such as the Human Phenotype Ontology, into network structures.\n",
    "- `functools.lru_cache`: Decorator for caching function results, improving performance when repeatedly querying or processing the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff8694",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6682b",
   "metadata": {},
   "source": [
    "### Step 2: Estimate the fuzzy score between the input term and the HPO term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2875dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fuzzy matching shim: prefer RapidFuzz; fallback to FuzzyWuzzy ---\n",
    "try:\n",
    "    from rapidfuzz import fuzz as _fuzz\n",
    "    from rapidfuzz import process as _process\n",
    "    _FUZZ_LIB = \"rapidfuzz\"\n",
    "except Exception:\n",
    "    # Fallback (ensure python-Levenshtein is installed for speed)\n",
    "    from fuzzywuzzy import fuzz as _fuzz\n",
    "    from fuzzywuzzy import process as _process\n",
    "    _FUZZ_LIB = \"fuzzywuzzy\"\n",
    "\n",
    "def fuzzy_extract_one(query, choices, scorer=None):\n",
    "    \"\"\"\n",
    "    Wrapper around extractOne with a unified return shape:\n",
    "    returns (match_str, score).\n",
    "    \"\"\"\n",
    "    if _FUZZ_LIB == \"rapidfuzz\":\n",
    "        # RapidFuzz returns (match, score, index). Default scorer ~ ratio\n",
    "        # You can set scorer=_fuzz.WRatio for WRatio behavior, or _fuzz.ratio.\n",
    "        match, score, _ = _process.extractOne(query, choices, scorer=scorer or _fuzz.ratio)\n",
    "        return match, score\n",
    "    else:\n",
    "        # FuzzyWuzzy returns (match, score)\n",
    "        match, score = _process.extractOne(query, choices, scorer=scorer or _fuzz.WRatio)\n",
    "        return match, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e44e08",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- RapidFuzz: ratio, partial_ratio, token_sort_ratio, WRatio are available; default above uses ratio.\n",
    "- FuzzyWuzzy: WRatio is a solid general-purpose scorer, hence the fallback default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da52dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_fuzzy_score(input_term: str, hpo_term: str) -> float:\n",
    "    \"\"\"\n",
    "    Return similarity score in [0, 100], using RapidFuzz if available,\n",
    "    otherwise FuzzyWuzzy (preferably with python-Levenshtein installed).\n",
    "    \"\"\"\n",
    "    if not isinstance(input_term, str):\n",
    "        raise ValueError(\"reported_term must be a string.\")\n",
    "    if not isinstance(hpo_term, str):\n",
    "        return 0.0\n",
    "    _, score = fuzzy_extract_one(input_term, [hpo_term])\n",
    "    # RapidFuzz and FuzzyWuzzy both output 0–100 scale\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724d5ea",
   "metadata": {},
   "source": [
    "### Step 3: Look up HPO synonyms and definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6ae2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Shared ontology loader (already in your notebook) ---\n",
    "import obonet\n",
    "from functools import lru_cache\n",
    "\n",
    "HPO_URL = \"http://purl.obolibrary.org/obo/hp.obo\"\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def load_graph():\n",
    "    \"\"\"Load and cache the HPO graph once per session.\"\"\"\n",
    "    return obonet.read_obo(HPO_URL)\n",
    "\n",
    "\n",
    "# --- Improved: fast, cached meta lookup ---\n",
    "@lru_cache(maxsize=8192)  # cache per-HPO-ID lookups, too\n",
    "def get_hpo_definitions_and_synonyms(hpo_id: str):\n",
    "    \"\"\"\n",
    "    Return (synonyms, definition) for an HPO ID using the cached graph.\n",
    "    - Avoids repeated obo downloads/parsing.\n",
    "    - Cleans OBO-quoted strings for readability.\n",
    "    \"\"\"\n",
    "    graph = load_graph()  # <-- reuse cached graph\n",
    "    node = graph.nodes.get(hpo_id)\n",
    "    if not node:\n",
    "        return [], None\n",
    "\n",
    "    # Synonyms: in OBO it’s usually 'synonym' (singular); keep a fallback.\n",
    "    raw_syn = node.get(\"synonym\", []) or node.get(\"synonyms\", [])\n",
    "\n",
    "    def _clean_obo_text(s: str) -> str:\n",
    "        # OBO annotation format often looks like:  \"\\\"text\\\" EXACT [XREF:...]\"\"\n",
    "        if isinstance(s, str) and '\"' in s:\n",
    "            try:\n",
    "                return s.split('\"', 2)[1]\n",
    "            except Exception:\n",
    "                return s\n",
    "        return s\n",
    "\n",
    "    synonyms = [_clean_obo_text(s) for s in raw_syn]\n",
    "\n",
    "    # Definition may be a single string like \"\\\"text\\\" [PMID:...]\"\"\n",
    "    raw_def = node.get(\"def\")\n",
    "    definition = _clean_obo_text(raw_def) if isinstance(raw_def, str) else None\n",
    "\n",
    "    return synonyms, definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2683c",
   "metadata": {},
   "source": [
    "### Step 4: Get full lineage for a given HPO ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65b3c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obonet\n",
    "from functools import lru_cache\n",
    "\n",
    "# HPO_URL = \"http://purl.obolibrary.org/obo/hp.obo\"\n",
    "\n",
    "# # Cache the graph so it loads only once\n",
    "# @lru_cache(maxsize=1)\n",
    "# def load_graph():\n",
    "#     return obonet.read_obo(HPO_URL)\n",
    "\n",
    "def get_rank_and_path(hpo_id):\n",
    "    \"\"\"\n",
    "    Return rank and path from root to this term (shortest path).\n",
    "    \"\"\"\n",
    "    graph = load_graph()\n",
    "    if hpo_id not in graph:\n",
    "        return None, []\n",
    "\n",
    "    path = [hpo_id]\n",
    "    depth = 0\n",
    "    current = hpo_id\n",
    "    while True:\n",
    "        parents = graph.nodes[current].get(\"is_a\", [])\n",
    "        if not parents:\n",
    "            break\n",
    "        current = parents[0]  # take first parent if multiple\n",
    "        path.append(current)\n",
    "        depth += 1\n",
    "        if current == \"HP:0000001\":\n",
    "            break\n",
    "    return depth, list(reversed(path)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa2917",
   "metadata": {},
   "source": [
    "### Normalizatoin and synonym mathcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77a2ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple, Optional\n",
    "try:\n",
    "    # Prefer RapidFuzz (faster, no GPL issues)\n",
    "    from rapidfuzz import fuzz, process as rf_process\n",
    "    _USE_RF = True\n",
    "except Exception:\n",
    "    # Fall back to fuzzywuzzy if RapidFuzz isn’t available\n",
    "    from fuzzywuzzy import fuzz, process as fw_process\n",
    "    _USE_RF = False\n",
    "\n",
    "def _norm(s: Optional[str]) -> str:\n",
    "    return (s or \"\").strip().lower()\n",
    "\n",
    "def synonym_matches_input(\n",
    "    input_symptom: str,\n",
    "    synonyms: Iterable[str],\n",
    "    exact: bool = True,\n",
    "    fuzzy_threshold: int = 90\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Return True if the input symptom matches any synonym (exact case-insensitive\n",
    "    or fuzzy >= threshold).\n",
    "    \"\"\"\n",
    "    inp = _norm(input_symptom)\n",
    "    syns = [_norm(s) for s in (synonyms or []) if s]\n",
    "\n",
    "    # Exact (case-insensitive)\n",
    "    if exact and inp in syns:\n",
    "        return True\n",
    "\n",
    "    # Fuzzy fallback if desired\n",
    "    if fuzzy_threshold is not None and len(syns) > 0:\n",
    "        if _USE_RF:\n",
    "            # RapidFuzz: compute max similarity quickly\n",
    "            # (rf_process.extractOne returns (match, score, idx))\n",
    "            _, score, _ = rf_process.extractOne(inp, syns, scorer=fuzz.ratio)\n",
    "            return score >= fuzzy_threshold\n",
    "        else:\n",
    "            # FuzzyWuzzy fallback\n",
    "            best, score = fw_process.extractOne(inp, syns)\n",
    "            return score >= fuzzy_threshold\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da967325",
   "metadata": {},
   "source": [
    "### Step 1: Map reported symptoms to HPO terms using the HPA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53620fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from typing import Iterable, Optional, Tuple, List, Dict\n",
    "\n",
    "\n",
    "\n",
    "def map_symptoms_to_hpo(\n",
    "    symptom: str,\n",
    "    timeout: int = 10,\n",
    "    retries: int = 2,\n",
    "    backoff: float = 0.7,\n",
    "    top_k: int = 5\n",
    ") -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Query the JAX HPO search API and return up to top_k candidates:\n",
    "    [{ \"name\": <term_name>, \"id\": <hpo_id> }, ...]\n",
    "    Returns [] on failure or no results.\n",
    "    \"\"\"\n",
    "    url = \"https://ontology.jax.org/api/hp/search/\"\n",
    "    params = {\"q\": symptom}\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            resp = requests.get(url, params=params, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            results = data.get(\"terms\", []) or []\n",
    "            # Trim to top_k if requested\n",
    "            out = []\n",
    "            for r in results[:max(1, top_k)]:\n",
    "                name = r.get(\"name\")\n",
    "                hpo_id = r.get(\"id\")\n",
    "                if name and hpo_id:\n",
    "                    out.append({\"name\": name, \"id\": hpo_id})\n",
    "            return out\n",
    "        except requests.exceptions.RequestException:\n",
    "            if attempt < retries:\n",
    "                time.sleep(backoff * (attempt + 1))\n",
    "                continue\n",
    "            return []\n",
    "        except ValueError:\n",
    "            return []\n",
    "\n",
    "\n",
    "def _score_candidate(\n",
    "    symptom: str,\n",
    "    cand_name: str,\n",
    "    cand_id: str,\n",
    "    score_scorer=None,\n",
    "    synonym_exact: bool = True,\n",
    "    synonym_fuzzy_threshold: int = 90\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Compute metrics for a candidate:\n",
    "    - fuzzy score (symptom vs candidate label)\n",
    "    - synonym match (exact/fuzzy)\n",
    "    - definition, rank, path for the candidate\n",
    "    \"\"\"\n",
    "    # Fuzzy similarity to the label\n",
    "    fuzzy_score = estimate_fuzzy_score(symptom, cand_name)\n",
    "\n",
    "    # Synonyms/definition\n",
    "    synonyms, definition = get_hpo_definitions_and_synonyms(cand_id)\n",
    "    syn_ok = synonym_matches_input(\n",
    "        input_symptom=symptom,\n",
    "        synonyms=synonyms,\n",
    "        exact=synonym_exact,\n",
    "        fuzzy_threshold=synonym_fuzzy_threshold\n",
    "    )\n",
    "\n",
    "    # Lineage\n",
    "    rank, path = get_rank_and_path(cand_id)\n",
    "\n",
    "    return {\n",
    "        \"name\": cand_name,\n",
    "        \"id\": cand_id,\n",
    "        \"fuzzy_score\": float(fuzzy_score),\n",
    "        \"syn_match\": bool(syn_ok),\n",
    "        \"definition\": definition,\n",
    "        \"rank\": rank,\n",
    "        \"path\": path or [],\n",
    "        \"synonyms\": synonyms,  # useful for debugging\n",
    "    }\n",
    "\n",
    "\n",
    "def _choose_best_candidate(\n",
    "    scored: List[Dict[str, object]],\n",
    "    score_threshold: int = 80\n",
    ") -> Optional[Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Pick the best candidate with the following priority:\n",
    "    1) Any candidate with syn_match=True and fuzzy_score >= score_threshold\n",
    "    2) Any candidate with syn_match=True (highest fuzzy_score wins)\n",
    "    3) Highest fuzzy_score candidate overall\n",
    "    \"\"\"\n",
    "    if not scored:\n",
    "        return None\n",
    "\n",
    "    # 1) syn match + score above threshold\n",
    "    tier1 = [c for c in scored if c[\"syn_match\"] and c[\"fuzzy_score\"] >= score_threshold]\n",
    "    if tier1:\n",
    "        return max(tier1, key=lambda c: c[\"fuzzy_score\"])\n",
    "\n",
    "    # 2) syn match (best fuzzy among them)\n",
    "    tier2 = [c for c in scored if c[\"syn_match\"]]\n",
    "    if tier2:\n",
    "        return max(tier2, key=lambda c: c[\"fuzzy_score\"])\n",
    "\n",
    "    # 3) best fuzzy overall\n",
    "    return max(scored, key=lambda c: c[\"fuzzy_score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1136e9",
   "metadata": {},
   "source": [
    "## Pipeline function to chain step 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce676598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_symptoms_to_hpo_pipeline(\n",
    "    symptom: str,\n",
    "    score_threshold: int = 80,\n",
    "    synonym_fuzzy_threshold: int = 90,\n",
    "    synonym_exact: bool = True,\n",
    "    top_k: int = 5,\n",
    "    return_debug: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate top-K candidates from API and choose the best per fuzzy/synonym logic.\n",
    "\n",
    "    Returns (always 8 fields):\n",
    "    1) reported_symptom : str\n",
    "    2) hpo_term         : str | None\n",
    "    3) hpo_id           : str | None\n",
    "    4) definition       : str | None\n",
    "    5) rank             : int | None\n",
    "    6) path             : list[str]\n",
    "    7) fuzzy_score      : float\n",
    "    8) status           : 'matched' | 'not matched'\n",
    "\n",
    "    If return_debug=True, also returns a 9th field:\n",
    "    9) debug_candidates : list[dict] with per-candidate scores & flags\n",
    "    \"\"\"\n",
    "    # Step 1: fetch candidates\n",
    "    candidates = map_symptoms_to_hpo(symptom, top_k=top_k)\n",
    "\n",
    "    if not candidates:\n",
    "        base = (symptom, None, None, None, None, [], 0.0, \"not matched\")\n",
    "        return (base + ([],)) if return_debug else base\n",
    "\n",
    "    # Step 2: score each candidate\n",
    "    scored = [\n",
    "        _score_candidate(\n",
    "            symptom=symptom,\n",
    "            cand_name=c[\"name\"],\n",
    "            cand_id=c[\"id\"],\n",
    "            synonym_exact=synonym_exact,\n",
    "            synonym_fuzzy_threshold=synonym_fuzzy_threshold,\n",
    "        )\n",
    "        for c in candidates\n",
    "    ]\n",
    "\n",
    "    # Step 3: choose best\n",
    "    best = _choose_best_candidate(scored, score_threshold=score_threshold)\n",
    "\n",
    "    if not best:\n",
    "        base = (symptom, None, None, None, None, [], 0.0, \"not matched\")\n",
    "        return (base + (scored,)) if return_debug else base\n",
    "\n",
    "    # Step 4: accept/reject\n",
    "    accept = (best[\"fuzzy_score\"] >= score_threshold) or best[\"syn_match\"]\n",
    "    status = \"matched\" if accept else \"not matched\"\n",
    "\n",
    "    result = (\n",
    "        symptom,\n",
    "        best[\"name\"],\n",
    "        best[\"id\"],\n",
    "        best[\"definition\"],\n",
    "        best[\"rank\"],\n",
    "        best[\"path\"],\n",
    "        float(best[\"fuzzy_score\"]),\n",
    "        status,\n",
    "    )\n",
    "    return (result + (scored,)) if return_debug else result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529d35e",
   "metadata": {},
   "source": [
    "### How to use (quick demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "939b0220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reported_symptom</th>\n",
       "      <th>hpo_term</th>\n",
       "      <th>hpo_id</th>\n",
       "      <th>definition</th>\n",
       "      <th>rank</th>\n",
       "      <th>path</th>\n",
       "      <th>fuzzy_score</th>\n",
       "      <th>status</th>\n",
       "      <th>debug_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptosis</td>\n",
       "      <td>Ptosis</td>\n",
       "      <td>HP:0000508</td>\n",
       "      <td>The upper eyelid margin is positioned 3 mm or ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[HP:0000001, HP:0000118, HP:0000478, HP:001237...</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>matched</td>\n",
       "      <td>[{'name': 'Ptosis', 'id': 'HP:0000508', 'fuzzy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weak suck</td>\n",
       "      <td>Weak cry</td>\n",
       "      <td>HP:0001612</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>[HP:0000001, HP:0000118, HP:0001608, HP:002542...</td>\n",
       "      <td>58.823529</td>\n",
       "      <td>not matched</td>\n",
       "      <td>[{'name': 'Weak grip', 'id': 'HP:0033466', 'fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exercise intolerance</td>\n",
       "      <td>Exercise intolerance</td>\n",
       "      <td>HP:0003546</td>\n",
       "      <td>A functional motor deficit where individuals w...</td>\n",
       "      <td>3</td>\n",
       "      <td>[HP:0000001, HP:0000118, HP:0025142, HP:0003546]</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>matched</td>\n",
       "      <td>[{'name': 'Exercise intolerance', 'id': 'HP:00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reported_symptom              hpo_term      hpo_id  \\\n",
       "0                ptosis                Ptosis  HP:0000508   \n",
       "1             weak suck              Weak cry  HP:0001612   \n",
       "2  exercise intolerance  Exercise intolerance  HP:0003546   \n",
       "\n",
       "                                          definition  rank  \\\n",
       "0  The upper eyelid margin is positioned 3 mm or ...     4   \n",
       "1                                               None     4   \n",
       "2  A functional motor deficit where individuals w...     3   \n",
       "\n",
       "                                                path  fuzzy_score  \\\n",
       "0  [HP:0000001, HP:0000118, HP:0000478, HP:001237...    83.333333   \n",
       "1  [HP:0000001, HP:0000118, HP:0001608, HP:002542...    58.823529   \n",
       "2   [HP:0000001, HP:0000118, HP:0025142, HP:0003546]    95.000000   \n",
       "\n",
       "        status                                   debug_candidates  \n",
       "0      matched  [{'name': 'Ptosis', 'id': 'HP:0000508', 'fuzzy...  \n",
       "1  not matched  [{'name': 'Weak grip', 'id': 'HP:0033466', 'fu...  \n",
       "2      matched  [{'name': 'Exercise intolerance', 'id': 'HP:00...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptoms = [\"ptosis\", \"weak suck\", \"exercise intolerance\"]\n",
    "rows = [map_symptoms_to_hpo_pipeline(s, top_k=8, return_debug=True) for s in symptoms]\n",
    "\n",
    "# Unpack for viewing\n",
    "import pandas as pd\n",
    "cols = [\"reported_symptom\",\"hpo_term\",\"hpo_id\",\"definition\",\"rank\",\"path\",\"fuzzy_score\",\"status\",\"debug_candidates\"]\n",
    "pd.DataFrame(rows, columns=cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
