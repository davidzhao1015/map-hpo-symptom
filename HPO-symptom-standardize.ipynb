{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2ab8f5",
   "metadata": {},
   "source": [
    "# Standardizing Clinical Symptom Terms with Human Phenotype Ontology (HPO) in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21fcb94",
   "metadata": {},
   "source": [
    "by Xin (David) Zhao  \n",
    "Created on September 19, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161724c2",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7043244e",
   "metadata": {},
   "source": [
    "Free-text symptom reporting in rare disease literature is often inconsistent, making it difficult to standardize information for literature reviews and evidence synthesis. This notebook demonstrates an automated pipeline that maps reported symptoms to Human Phenotype Ontology (HPO) terms, verified using natural language processing techniques. The pipeline takes only reported symptoms as input and produces a structured table of standardized terms (or synonyms) enriched with HPO IDs, definitions, and ontology hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756ae22",
   "metadata": {},
   "source": [
    "## Backgroud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057cf93",
   "metadata": {},
   "source": [
    "In literature reviews and evidence synthesis for rare diseases, clinical symptoms are often reported in non-standardized ways, making it difficult to compare or merge them computationally.\n",
    "\n",
    "This real-world challenge motivated us to develop a data solution for standardizing free-text symptom reports. Using the open-source Human Phenotype Ontology (HPO) and its API, we can map reported symptoms to controlled ontology terms, with the process automated in Python.\n",
    "\n",
    "I streamlined the workflow into several steps: retrieving candidate HPO terms and synonyms, linking them to IDs and definitions, and applying fuzzy matching to identify similarities between reported symptoms and retrieved HPO terms. This notebook demonstrates the pipeline with minimal documentation as a reference for the community.\n",
    "\n",
    "The workflow has been tested in a real-world project. While effective, there remain opportunities to refine and expand the approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418fc71",
   "metadata": {},
   "source": [
    "## Alogrithm explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbc8bc",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "Standardize free-text clinical symptoms by mapping them to HPO (Human Phenotype Ontology) terms, then verify and contextualize each match.\n",
    "\n",
    "**Inputs**: symptom (str): A reported, free-text symptom (e.g., “ptosis”, “muscle weakness”).\n",
    "\n",
    "**External resources & libs**\n",
    "- Search API: https://ontology.jax.org/api/hp/search/?q=<symptom> (top result taken)\n",
    "- Ontology file: http://purl.obolibrary.org/obo/hp.obo (definitions, synonyms, hierarchy)\n",
    "- Python libs: requests, fuzzywuzzy.process.extractOne, obonet, functools.lru_cache, pandas (optional)\n",
    "\n",
    "**High-level flow**\n",
    "1. Search HPO: Query the JAX HPO API with the input symptom → get top candidate (name, id) or no result.\n",
    "2.\tFuzzy validation: Compute a fuzzy score between the input symptom and the returned HPO term name.\n",
    "3.\tContext retrieval: From hp.obo, pull definition and synonyms for the candidate HPO ID.\n",
    "4.\tLineage extraction: From the same ontology graph, compute depth and path to root HP:0000001 (using first parent if multiple).\n",
    "5.\tAccept/Reject decision\n",
    "\t- Accept if fuzzy_score ≥ 80 OR HPO name appears in its synonyms (case-insensitive check).\n",
    "\t- Reject otherwise (or if API/ontology lookup fails).\n",
    "\n",
    "**Decision rule (acceptance)**\n",
    "- Threshold: fuzzy_score ≥ 80\n",
    "- Synonym override: Accept if HPO term name is present among its synonyms (case-insensitive)\n",
    "\n",
    "**Rationale**: Puts speed/recall first (top hit) with a sanity check on similarity; adds semantic cushion via synonyms.\n",
    "\n",
    "**Outputs (as implemented)**\n",
    "\n",
    "The pipeline returns 8 fields in fixed order:  \n",
    "1. reported_symptom (str) \n",
    "2.\thpo_term (str | None) \n",
    "3.\thpo_id (str | None)\n",
    "4.\tdefinition (str | None)\n",
    "5.\trank (int | None)\n",
    "6.\tpath (list[str] | [])\n",
    "7.\tfuzzy_score (int | 0)\n",
    "8.\tstatus (“matched” | “not matched”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb049ea",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee11e8",
   "metadata": {},
   "source": [
    "### Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14b75225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Iterable, Optional\n",
    "\n",
    "# Specific modules\n",
    "import rapidfuzz\n",
    "from fuzzywuzzy import process\n",
    "import obonet\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130fd4c",
   "metadata": {},
   "source": [
    "### Notes on Libraries\n",
    "\n",
    "- `rapidfuzz`: A fast Python library for fuzzy string matching. It measures text similarity (e.g., Levenshtein distance) to see how closely a reported symptom matches HPO terms or synonyms. It’s preferred over fuzzywuzzy because it is faster and has more permissive licensing.\n",
    "- `fuzzywuzzy.process`: A fuzzy string matching utility that compares free-text symptoms with HPO terms or synonyms. Useful as a fallback when rapidfuzz is not available.\n",
    "- `obonet`: A library for loading and parsing OBO ontology files, such as the Human Phenotype Ontology, and representing them as network structures for easy traversal.\n",
    "- `functools.lru_cache`: A Python decorator that caches function results to speed up repeated calls, improving performance when querying or processing the same data multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff8694",
   "metadata": {},
   "source": [
    "## Implementation Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee83769",
   "metadata": {},
   "source": [
    "### Step 1. Candidate Retrieval (API query with retries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93e54183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from typing import Iterable, Optional, Tuple, List, Dict\n",
    "\n",
    "\n",
    "\n",
    "def map_symptoms_to_hpo(\n",
    "    symptom: str,\n",
    "    timeout: int = 10,\n",
    "    retries: int = 2,\n",
    "    backoff: float = 0.7,\n",
    "    top_k: int = 5\n",
    ") -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Query the JAX HPO search API and return up to top_k candidates:\n",
    "    [{ \"name\": <term_name>, \"id\": <hpo_id> }, ...]\n",
    "    Returns [] on failure or no results.\n",
    "    \"\"\"\n",
    "    url = \"https://ontology.jax.org/api/hp/search/\"\n",
    "    params = {\"q\": symptom}\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            resp = requests.get(url, params=params, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            results = data.get(\"terms\", []) or []\n",
    "            # Trim to top_k if requested\n",
    "            out = []\n",
    "            for r in results[:max(1, top_k)]:\n",
    "                name = r.get(\"name\")\n",
    "                hpo_id = r.get(\"id\")\n",
    "                if name and hpo_id:\n",
    "                    out.append({\"name\": name, \"id\": hpo_id})\n",
    "            return out\n",
    "        except requests.exceptions.RequestException:\n",
    "            if attempt < retries:\n",
    "                time.sleep(backoff * (attempt + 1))\n",
    "                continue\n",
    "            return []\n",
    "        except ValueError:\n",
    "            return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6682b",
   "metadata": {},
   "source": [
    "### Step 2. Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2875dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fuzzy matching shim: prefer RapidFuzz; fallback to FuzzyWuzzy ---\n",
    "try:\n",
    "    from rapidfuzz import fuzz as _fuzz\n",
    "    from rapidfuzz import process as _process\n",
    "    _FUZZ_LIB = \"rapidfuzz\"\n",
    "except Exception:\n",
    "    # Fallback (ensure python-Levenshtein is installed for speed)\n",
    "    from fuzzywuzzy import fuzz as _fuzz\n",
    "    from fuzzywuzzy import process as _process\n",
    "    _FUZZ_LIB = \"fuzzywuzzy\"\n",
    "\n",
    "def fuzzy_extract_one(query, choices, scorer=None):\n",
    "    \"\"\"\n",
    "    Wrapper around extractOne with a unified return shape:\n",
    "    returns (match_str, score).\n",
    "    \"\"\"\n",
    "    if _FUZZ_LIB == \"rapidfuzz\":\n",
    "        # RapidFuzz returns (match, score, index). Default scorer ~ ratio\n",
    "        # You can set scorer=_fuzz.WRatio for WRatio behavior, or _fuzz.ratio.\n",
    "        match, score, _ = _process.extractOne(query, choices, scorer=scorer or _fuzz.ratio)\n",
    "        return match, score\n",
    "    else:\n",
    "        # FuzzyWuzzy returns (match, score)\n",
    "        match, score = _process.extractOne(query, choices, scorer=scorer or _fuzz.WRatio)\n",
    "        return match, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e44e08",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- RapidFuzz: ratio, partial_ratio, token_sort_ratio, WRatio are available; default above uses ratio.\n",
    "- FuzzyWuzzy: WRatio is a solid general-purpose scorer, hence the fallback default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da52dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_fuzzy_score(input_term: str, hpo_term: str) -> float:\n",
    "    \"\"\"\n",
    "    Return similarity score in [0, 100], using RapidFuzz if available,\n",
    "    otherwise FuzzyWuzzy (preferably with python-Levenshtein installed).\n",
    "    \"\"\"\n",
    "    if not isinstance(input_term, str):\n",
    "        raise ValueError(\"reported_term must be a string.\")\n",
    "    if not isinstance(hpo_term, str):\n",
    "        return 0.0\n",
    "    _, score = fuzzy_extract_one(input_term, [hpo_term])\n",
    "    # RapidFuzz and FuzzyWuzzy both output 0–100 scale\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724d5ea",
   "metadata": {},
   "source": [
    "### Step 3. Synonym & Definition Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6ae2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Shared ontology loader (already in your notebook) ---\n",
    "import obonet\n",
    "from functools import lru_cache\n",
    "\n",
    "HPO_URL = \"http://purl.obolibrary.org/obo/hp.obo\"\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def load_graph():\n",
    "    \"\"\"Load and cache the HPO graph once per session.\"\"\"\n",
    "    return obonet.read_obo(HPO_URL)\n",
    "\n",
    "\n",
    "# --- Improved: fast, cached meta lookup ---\n",
    "@lru_cache(maxsize=8192)  # cache per-HPO-ID lookups, too\n",
    "def get_hpo_definitions_and_synonyms(hpo_id: str):\n",
    "    \"\"\"\n",
    "    Return (synonyms, definition) for an HPO ID using the cached graph.\n",
    "    - Avoids repeated obo downloads/parsing.\n",
    "    - Cleans OBO-quoted strings for readability.\n",
    "    \"\"\"\n",
    "    graph = load_graph()  # <-- reuse cached graph\n",
    "    node = graph.nodes.get(hpo_id)\n",
    "    if not node:\n",
    "        return [], None\n",
    "\n",
    "    # Synonyms: in OBO it’s usually 'synonym' (singular); keep a fallback.\n",
    "    raw_syn = node.get(\"synonym\", []) or node.get(\"synonyms\", [])\n",
    "\n",
    "    def _clean_obo_text(s: str) -> str:\n",
    "        # OBO annotation format often looks like:  \"\\\"text\\\" EXACT [XREF:...]\"\"\n",
    "        if isinstance(s, str) and '\"' in s:\n",
    "            try:\n",
    "                return s.split('\"', 2)[1]\n",
    "            except Exception:\n",
    "                return s\n",
    "        return s\n",
    "\n",
    "    synonyms = [_clean_obo_text(s) for s in raw_syn]\n",
    "\n",
    "    # Definition may be a single string like \"\\\"text\\\" [PMID:...]\"\"\n",
    "    raw_def = node.get(\"def\")\n",
    "    definition = _clean_obo_text(raw_def) if isinstance(raw_def, str) else None\n",
    "\n",
    "    return synonyms, definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2683c",
   "metadata": {},
   "source": [
    "### Step 4. Ontology Lineage Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65b3c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obonet\n",
    "from functools import lru_cache\n",
    "\n",
    "# HPO_URL = \"http://purl.obolibrary.org/obo/hp.obo\"\n",
    "\n",
    "# # Cache the graph so it loads only once\n",
    "# @lru_cache(maxsize=1)\n",
    "# def load_graph():\n",
    "#     return obonet.read_obo(HPO_URL)\n",
    "\n",
    "def get_rank_and_path(hpo_id):\n",
    "    \"\"\"\n",
    "    Return rank and path from root to this term (shortest path).\n",
    "    \"\"\"\n",
    "    graph = load_graph()\n",
    "    if hpo_id not in graph:\n",
    "        return None, []\n",
    "\n",
    "    path = [hpo_id]\n",
    "    depth = 0\n",
    "    current = hpo_id\n",
    "    while True:\n",
    "        parents = graph.nodes[current].get(\"is_a\", [])\n",
    "        if not parents:\n",
    "            break\n",
    "        current = parents[0]  # take first parent if multiple\n",
    "        path.append(current)\n",
    "        depth += 1\n",
    "        if current == \"HP:0000001\":\n",
    "            break\n",
    "    return depth, list(reversed(path)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa2917",
   "metadata": {},
   "source": [
    "### Step 5. Synonym Matching Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77a2ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple, Optional\n",
    "try:\n",
    "    # Prefer RapidFuzz (faster, no GPL issues)\n",
    "    from rapidfuzz import fuzz, process as rf_process\n",
    "    _USE_RF = True\n",
    "except Exception:\n",
    "    # Fall back to fuzzywuzzy if RapidFuzz isn’t available\n",
    "    from fuzzywuzzy import fuzz, process as fw_process\n",
    "    _USE_RF = False\n",
    "\n",
    "def _norm(s: Optional[str]) -> str:\n",
    "    return (s or \"\").strip().lower()\n",
    "\n",
    "def synonym_matches_input(\n",
    "    input_symptom: str,\n",
    "    synonyms: Iterable[str],\n",
    "    exact: bool = True,\n",
    "    fuzzy_threshold: int = 90\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Return True if the input symptom matches any synonym (exact case-insensitive\n",
    "    or fuzzy >= threshold).\n",
    "    \"\"\"\n",
    "    inp = _norm(input_symptom)\n",
    "    syns = [_norm(s) for s in (synonyms or []) if s]\n",
    "\n",
    "    # Exact (case-insensitive)\n",
    "    if exact and inp in syns:\n",
    "        return True\n",
    "\n",
    "    # Fuzzy fallback if desired\n",
    "    if fuzzy_threshold is not None and len(syns) > 0:\n",
    "        if _USE_RF:\n",
    "            # RapidFuzz: compute max similarity quickly\n",
    "            # (rf_process.extractOne returns (match, score, idx))\n",
    "            _, score, _ = rf_process.extractOne(inp, syns, scorer=fuzz.ratio)\n",
    "            return score >= fuzzy_threshold\n",
    "        else:\n",
    "            # FuzzyWuzzy fallback\n",
    "            best, score = fw_process.extractOne(inp, syns)\n",
    "            return score >= fuzzy_threshold\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2328d54",
   "metadata": {},
   "source": [
    "### Step 6. Candidate Scoring & Best Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2541b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _score_candidate(\n",
    "    symptom: str,\n",
    "    cand_name: str,\n",
    "    cand_id: str,\n",
    "    score_scorer=None,\n",
    "    synonym_exact: bool = True,\n",
    "    synonym_fuzzy_threshold: int = 90\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Compute metrics for a candidate:\n",
    "    - fuzzy score (symptom vs candidate label)\n",
    "    - synonym match (exact/fuzzy)\n",
    "    - definition, rank, path for the candidate\n",
    "    \"\"\"\n",
    "    # Fuzzy similarity to the label\n",
    "    fuzzy_score = estimate_fuzzy_score(symptom, cand_name)\n",
    "\n",
    "    # Synonyms/definition\n",
    "    synonyms, definition = get_hpo_definitions_and_synonyms(cand_id)\n",
    "    syn_ok = synonym_matches_input(\n",
    "        input_symptom=symptom,\n",
    "        synonyms=synonyms,\n",
    "        exact=synonym_exact,\n",
    "        fuzzy_threshold=synonym_fuzzy_threshold\n",
    "    )\n",
    "\n",
    "    # Lineage\n",
    "    rank, path = get_rank_and_path(cand_id)\n",
    "\n",
    "    return {\n",
    "        \"name\": cand_name,\n",
    "        \"id\": cand_id,\n",
    "        \"fuzzy_score\": float(fuzzy_score),\n",
    "        \"syn_match\": bool(syn_ok),\n",
    "        \"definition\": definition,\n",
    "        \"rank\": rank,\n",
    "        \"path\": path or [],\n",
    "        \"synonyms\": synonyms,  # useful for debugging\n",
    "    }\n",
    "\n",
    "\n",
    "def _choose_best_candidate(\n",
    "    scored: List[Dict[str, object]],\n",
    "    score_threshold: int = 80\n",
    ") -> Optional[Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Pick the best candidate with the following priority:\n",
    "    1) Any candidate with syn_match=True and fuzzy_score >= score_threshold\n",
    "    2) Any candidate with syn_match=True (highest fuzzy_score wins)\n",
    "    3) Highest fuzzy_score candidate overall\n",
    "    \"\"\"\n",
    "    if not scored:\n",
    "        return None\n",
    "\n",
    "    # 1) syn match + score above threshold\n",
    "    tier1 = [c for c in scored if c[\"syn_match\"] and c[\"fuzzy_score\"] >= score_threshold]\n",
    "    if tier1:\n",
    "        return max(tier1, key=lambda c: c[\"fuzzy_score\"])\n",
    "\n",
    "    # 2) syn match (best fuzzy among them)\n",
    "    tier2 = [c for c in scored if c[\"syn_match\"]]\n",
    "    if tier2:\n",
    "        return max(tier2, key=lambda c: c[\"fuzzy_score\"])\n",
    "\n",
    "    # 3) best fuzzy overall\n",
    "    return max(scored, key=lambda c: c[\"fuzzy_score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1136e9",
   "metadata": {},
   "source": [
    "## Step 7. End-to-End Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce676598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_symptoms_to_hpo_pipeline(\n",
    "    symptom: str,\n",
    "    score_threshold: int = 80,\n",
    "    synonym_fuzzy_threshold: int = 90,\n",
    "    synonym_exact: bool = True,\n",
    "    top_k: int = 5,\n",
    "    return_debug: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate top-K candidates from API and choose the best per fuzzy/synonym logic.\n",
    "\n",
    "    Returns (always 8 fields):\n",
    "    1) reported_symptom : str\n",
    "    2) hpo_term         : str | None\n",
    "    3) hpo_id           : str | None\n",
    "    4) definition       : str | None\n",
    "    5) rank             : int | None\n",
    "    6) path             : list[str]\n",
    "    7) fuzzy_score      : float\n",
    "    8) status           : 'matched' | 'not matched'\n",
    "\n",
    "    If return_debug=True, also returns a 9th field:\n",
    "    9) debug_candidates : list[dict] with per-candidate scores & flags\n",
    "    \"\"\"\n",
    "    # Step 1: fetch candidates\n",
    "    candidates = map_symptoms_to_hpo(symptom, top_k=top_k)\n",
    "\n",
    "    if not candidates:\n",
    "        base = (symptom, None, None, None, None, [], 0.0, \"not matched\")\n",
    "        return (base + ([],)) if return_debug else base\n",
    "\n",
    "    # Step 2: score each candidate\n",
    "    scored = [\n",
    "        _score_candidate(\n",
    "            symptom=symptom,\n",
    "            cand_name=c[\"name\"],\n",
    "            cand_id=c[\"id\"],\n",
    "            synonym_exact=synonym_exact,\n",
    "            synonym_fuzzy_threshold=synonym_fuzzy_threshold,\n",
    "        )\n",
    "        for c in candidates\n",
    "    ]\n",
    "\n",
    "    # Step 3: choose best\n",
    "    best = _choose_best_candidate(scored, score_threshold=score_threshold)\n",
    "\n",
    "    if not best:\n",
    "        base = (symptom, None, None, None, None, [], 0.0, \"not matched\")\n",
    "        return (base + (scored,)) if return_debug else base\n",
    "\n",
    "    # Step 4: accept/reject\n",
    "    accept = (best[\"fuzzy_score\"] >= score_threshold) or best[\"syn_match\"]\n",
    "    status = \"matched\" if accept else \"not matched\"\n",
    "\n",
    "    result = (\n",
    "        symptom,\n",
    "        best[\"name\"],\n",
    "        best[\"id\"],\n",
    "        best[\"definition\"],\n",
    "        best[\"rank\"],\n",
    "        best[\"path\"],\n",
    "        float(best[\"fuzzy_score\"]),\n",
    "        status,\n",
    "    )\n",
    "    return (result + (scored,)) if return_debug else result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529d35e",
   "metadata": {},
   "source": [
    "## Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad6761",
   "metadata": {},
   "source": [
    "### Quick Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "939b0220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reported_symptom</th>\n",
       "      <th>hpo_term</th>\n",
       "      <th>hpo_id</th>\n",
       "      <th>definition</th>\n",
       "      <th>rank</th>\n",
       "      <th>path</th>\n",
       "      <th>fuzzy_score</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptosis</td>\n",
       "      <td>Ptosis</td>\n",
       "      <td>HP:0000508</td>\n",
       "      <td>The upper eyelid margin is positioned 3 mm or ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[HP:0000001, HP:0000118, HP:0000478, HP:001237...</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weak suck</td>\n",
       "      <td>Weak cry</td>\n",
       "      <td>HP:0001612</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>[HP:0000001, HP:0000118, HP:0001608, HP:002542...</td>\n",
       "      <td>58.823529</td>\n",
       "      <td>not matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exercise intolerance</td>\n",
       "      <td>Exercise intolerance</td>\n",
       "      <td>HP:0003546</td>\n",
       "      <td>A functional motor deficit where individuals w...</td>\n",
       "      <td>3</td>\n",
       "      <td>[HP:0000001, HP:0000118, HP:0025142, HP:0003546]</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reported_symptom              hpo_term      hpo_id  \\\n",
       "0                ptosis                Ptosis  HP:0000508   \n",
       "1             weak suck              Weak cry  HP:0001612   \n",
       "2  exercise intolerance  Exercise intolerance  HP:0003546   \n",
       "\n",
       "                                          definition  rank  \\\n",
       "0  The upper eyelid margin is positioned 3 mm or ...     4   \n",
       "1                                               None     4   \n",
       "2  A functional motor deficit where individuals w...     3   \n",
       "\n",
       "                                                path  fuzzy_score       status  \n",
       "0  [HP:0000001, HP:0000118, HP:0000478, HP:001237...    83.333333      matched  \n",
       "1  [HP:0000001, HP:0000118, HP:0001608, HP:002542...    58.823529  not matched  \n",
       "2   [HP:0000001, HP:0000118, HP:0025142, HP:0003546]    95.000000      matched  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptoms = [\"ptosis\", \"weak suck\", \"exercise intolerance\"]\n",
    "rows = [map_symptoms_to_hpo_pipeline(s, top_k=8, return_debug=False) for s in symptoms]\n",
    "\n",
    "# Unpack for viewing\n",
    "import pandas as pd\n",
    "cols = [\"reported_symptom\",\"hpo_term\",\"hpo_id\",\"definition\",\"rank\",\"path\",\"fuzzy_score\",\"status\"]\n",
    "pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad1fe1",
   "metadata": {},
   "source": [
    "### Optional Debug View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1011428e",
   "metadata": {},
   "source": [
    "Show `return_debug`=True mode to inspect candidate ranking.\n",
    "\n",
    "Setting return_debug=True in map_symptoms_to_hpo_pipeline makes the function return an extra field: a list of all candidate HPO matches with their scores, synonym flags, and metadata. This helps you inspect and debug how each candidate was evaluated, instead of just getting the best match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ptosis',\n",
       " 'Ptosis',\n",
       " 'HP:0000508',\n",
       " 'The upper eyelid margin is positioned 3 mm or more lower than usual and covers the superior portion of the iris (objective); or, the upper lid margin obscures at least part of the pupil (subjective).',\n",
       " 4,\n",
       " ['HP:0000001', 'HP:0000118', 'HP:0000478', 'HP:0012373', 'HP:0000508'],\n",
       " 83.33333333333334,\n",
       " 'matched',\n",
       " [{'name': 'Ptosis',\n",
       "   'id': 'HP:0000508',\n",
       "   'fuzzy_score': 83.33333333333334,\n",
       "   'syn_match': False,\n",
       "   'definition': 'The upper eyelid margin is positioned 3 mm or more lower than usual and covers the superior portion of the iris (objective); or, the upper lid margin obscures at least part of the pupil (subjective).',\n",
       "   'rank': 4,\n",
       "   'path': ['HP:0000001',\n",
       "    'HP:0000118',\n",
       "    'HP:0000478',\n",
       "    'HP:0012373',\n",
       "    'HP:0000508'],\n",
       "   'synonyms': ['Blepharoptosis',\n",
       "    'Drooping upper eyelid',\n",
       "    'Eye drop',\n",
       "    'Eyelid ptosis',\n",
       "    'Palpebral ptosis']},\n",
       "  {'name': 'Congenital bilateral ptosis',\n",
       "   'id': 'HP:0007911',\n",
       "   'fuzzy_score': 36.36363636363637,\n",
       "   'syn_match': False,\n",
       "   'definition': None,\n",
       "   'rank': 6,\n",
       "   'path': ['HP:0000001',\n",
       "    'HP:0000118',\n",
       "    'HP:0000478',\n",
       "    'HP:0012373',\n",
       "    'HP:0000508',\n",
       "    'HP:0001488',\n",
       "    'HP:0007911'],\n",
       "   'synonyms': ['Congenital drooping of both upper eyelids',\n",
       "    'Ptosis, bilateral congenital',\n",
       "    'Ptosis, congenital bilateral']},\n",
       "  {'name': 'Congenital ptosis',\n",
       "   'id': 'HP:0007970',\n",
       "   'fuzzy_score': 52.17391304347826,\n",
       "   'syn_match': False,\n",
       "   'definition': None,\n",
       "   'rank': 5,\n",
       "   'path': ['HP:0000001',\n",
       "    'HP:0000118',\n",
       "    'HP:0000478',\n",
       "    'HP:0012373',\n",
       "    'HP:0000508',\n",
       "    'HP:0007970'],\n",
       "   'synonyms': ['Congenital drooping upper eyelid']},\n",
       "  {'name': 'Progressive ptosis',\n",
       "   'id': 'HP:0007838',\n",
       "   'fuzzy_score': 50.0,\n",
       "   'syn_match': False,\n",
       "   'definition': 'A progressive form of ptosis.',\n",
       "   'rank': 5,\n",
       "   'path': ['HP:0000001',\n",
       "    'HP:0000118',\n",
       "    'HP:0000478',\n",
       "    'HP:0012373',\n",
       "    'HP:0000508',\n",
       "    'HP:0007838'],\n",
       "   'synonyms': ['Progressive drooping of upper eyelid']},\n",
       "  {'name': 'Unilateral ptosis',\n",
       "   'id': 'HP:0007687',\n",
       "   'fuzzy_score': 52.17391304347826,\n",
       "   'syn_match': False,\n",
       "   'definition': 'A unilateral form of ptosis.',\n",
       "   'rank': 5,\n",
       "   'path': ['HP:0000001',\n",
       "    'HP:0000118',\n",
       "    'HP:0000478',\n",
       "    'HP:0012373',\n",
       "    'HP:0000508',\n",
       "    'HP:0007687'],\n",
       "   'synonyms': ['Dropping of one upper eyelid']},\n",
       "  {'name': 'Bilateral ptosis',\n",
       "   'id': 'HP:0001488',\n",
       "   'fuzzy_score': 54.54545454545454,\n",
       "   'syn_match': False,\n",
       "   'definition': None,\n",
       "   'rank': 5,\n",
       "   'path': ['HP:0000001',\n",
       "    'HP:0000118',\n",
       "    'HP:0000478',\n",
       "    'HP:0012373',\n",
       "    'HP:0000508',\n",
       "    'HP:0001488'],\n",
       "   'synonyms': ['Drooping of both upper eyelids']},\n",
       "  {'name': 'Brow ptosis',\n",
       "   'id': 'HP:0031623',\n",
       "   'fuzzy_score': 70.58823529411764,\n",
       "   'syn_match': False,\n",
       "   'definition': 'Drooping of the upper eyebrow below the superior orbital rim.',\n",
       "   'rank': 6,\n",
       "   'path': ['HP:0000001',\n",
       "    'HP:0000118',\n",
       "    'HP:0001574',\n",
       "    'HP:0011138',\n",
       "    'HP:0001595',\n",
       "    'HP:0000534',\n",
       "    'HP:0031623'],\n",
       "   'synonyms': ['Drooping brow']},\n",
       "  {'name': 'Nephroptosis',\n",
       "   'id': 'HP:0011126',\n",
       "   'fuzzy_score': 66.66666666666667,\n",
       "   'syn_match': False,\n",
       "   'definition': 'A significant descent of the kidney as the patient moves from the supine to the erect position.',\n",
       "   'rank': 8,\n",
       "   'path': ['HP:0000001',\n",
       "    'HP:0000118',\n",
       "    'HP:0000119',\n",
       "    'HP:0000079',\n",
       "    'HP:0010935',\n",
       "    'HP:0000077',\n",
       "    'HP:0012210',\n",
       "    'HP:0100542',\n",
       "    'HP:0011126'],\n",
       "   'synonyms': ['Floating kidney', 'Renal ptosis']}])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_symptoms_to_hpo_pipeline('ptosis', top_k=8, return_debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b3da6",
   "metadata": {},
   "source": [
    "## Limitation and Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f32299",
   "metadata": {},
   "source": [
    "- API reliability (timeouts, availability).\n",
    "- Only first parent used in lineage.\n",
    "- Threshold tuning needed for different datasets.\n",
    "- Future directions:\n",
    "    - Evaluate **top-K candidates** (already implemented).\n",
    "    - Use semantic embeddings for trickier matches.\n",
    "    - Crosswalk to other vocabularies (MeSH, UMLS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b3c7a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20404e9",
   "metadata": {},
   "source": [
    "- Pipeline values: Reproducible, structured mapping\n",
    "- Direct applicability to rare-disease evidence synthesis\n",
    "- Extensibility for other biomedical text-mining tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0071c4",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c04a2",
   "metadata": {},
   "source": [
    "### References and Links\n",
    "\n",
    "- HPO API: https://ontology.jax.org/api/hp/search/\n",
    "- HPO Ontology file: http://purl.obolibrary.org/obo/hp.obo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5efa13",
   "metadata": {},
   "source": [
    "### Glossary\n",
    "\n",
    "- HPO ID: Unique identifier for phenotype\n",
    "- Fuzzy score: Similarity between two strings, 0-100 scale\n",
    "- Synonym override: Acceptance rule if input matches a known synonym"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
