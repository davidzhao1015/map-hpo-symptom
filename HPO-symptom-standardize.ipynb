{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2ab8f5",
   "metadata": {},
   "source": [
    "# Standardizing Clinical Symptoms of Rare Disease with Human Phenotype Ontology (HPO) in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161724c2",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916fbda",
   "metadata": {},
   "source": [
    "In literature reviews and evidence synthesis for rare diseases, clinical symptoms are often reported in non-standardized ways, making it difficult to compare or merge them computationally.\n",
    "\n",
    "This real-world challenge motivated us to develop a data solution for standardizing free-text symptom reports. Using the open-source Human Phenotype Ontology (HPO) and its API, we can map reported symptoms to controlled ontology terms, with the process automated in Python.\n",
    "\n",
    "I streamlined the workflow into several steps: retrieving candidate HPO terms and synonyms, linking them to IDs and definitions, and applying fuzzy matching to identify similarities between reported symptoms and retrieved HPO terms. This notebook demonstrates the pipeline with minimal documentation as a reference for the community.\n",
    "\n",
    "The workflow has been tested in a real-world project on congenital myasthenic syndromes (CMS). While effective, there remain opportunities to refine and expand the approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418fc71",
   "metadata": {},
   "source": [
    "## Alogrithm explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbc8bc",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "Standardize free-text clinical symptoms by mapping them to HPO (Human Phenotype Ontology) terms, then verify and contextualize each match.\n",
    "\n",
    "**Inputs**: symptom (str): A reported, free-text symptom (e.g., “ptosis”, “muscle weakness”).\n",
    "\n",
    "**External resources & libs**\n",
    "- Search API: https://ontology.jax.org/api/hp/search/?q=<symptom> (top result taken)\n",
    "- Ontology file: http://purl.obolibrary.org/obo/hp.obo (definitions, synonyms, hierarchy)\n",
    "- Python libs: requests, fuzzywuzzy.process.extractOne, obonet, functools.lru_cache, pandas (optional)\n",
    "\n",
    "**High-level flow**\n",
    "1. Search HPO: Query the JAX HPO API with the input symptom → get top candidate (name, id) or no result.\n",
    "2.\tFuzzy validation: Compute a fuzzy score between the input symptom and the returned HPO term name.\n",
    "3.\tContext retrieval: From hp.obo, pull definition and synonyms for the candidate HPO ID.\n",
    "4.\tLineage extraction: From the same ontology graph, compute depth and path to root HP:0000001 (using first parent if multiple).\n",
    "5.\tAccept/Reject decision\n",
    "\t- Accept if fuzzy_score ≥ 80 OR HPO name appears in its synonyms (case-insensitive check).\n",
    "\t- Reject otherwise (or if API/ontology lookup fails).\n",
    "\n",
    "**Decision rule (acceptance)**\n",
    "- Threshold: fuzzy_score ≥ 80\n",
    "- Synonym override: Accept if HPO term name is present among its synonyms (case-insensitive)\n",
    "\n",
    "**Rationale**: Puts speed/recall first (top hit) with a sanity check on similarity; adds semantic cushion via synonyms.\n",
    "\n",
    "**Outputs (as implemented)**\n",
    "\n",
    "The pipeline returns 8 fields in fixed order:  \n",
    "1. reported_symptom (str) \n",
    "2.\thpo_term (str | None) \n",
    "3.\thpo_id (str | None)\n",
    "4.\tdefinition (str | None)\n",
    "5.\trank (int | None)\n",
    "6.\tpath (list[str] | [])\n",
    "7.\tfuzzy_score (int | 0)\n",
    "8.\tstatus (“matched” | “not matched”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb049ea",
   "metadata": {},
   "source": [
    "## Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b75225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# General modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Specific modules\n",
    "from fuzzywuzzy import process\n",
    "import obonet\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130fd4c",
   "metadata": {},
   "source": [
    "**Brief information for the specific modules**\n",
    "\n",
    "- `fuzzywuzzy.process`: Provides fuzzy string matching, useful for comparing free-text symptoms to HPO terms and synonyms.\n",
    "- `obonet`: Loads and parses OBO-formatted ontology files, such as the Human Phenotype Ontology, into network structures.\n",
    "- `functools.lru_cache`: Decorator for caching function results, improving performance when repeatedly querying or processing the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff8694",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff7287f",
   "metadata": {},
   "source": [
    "### Step 1: Map reported symptoms to HPO terms using the HPA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def map_symptoms_to_hpo(symptom):\n",
    "    \"\"\"\n",
    "    Map reported symptoms to HPO terms using the HPA API.\n",
    "    \"\"\"\n",
    "    url = f\"https://ontology.jax.org/api/hp/search/?q={symptom}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # raises HTTPError if not 200 OK\n",
    "        json_data = response.json()\n",
    "        results = json_data.get('terms', [])\n",
    "        if results:\n",
    "            top = results[0]  # Take top result\n",
    "            return (top[\"name\"], top[\"id\"])  # return matched term and HPO ID as a tuple\n",
    "        else:\n",
    "            return (None, None)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return (None, None)\n",
    "    except ValueError as ve:\n",
    "        return (None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0086224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Headache', 'HP:0002315')\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "symptom = \"headache\"\n",
    "print(map_symptoms_to_hpo(symptom))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6682b",
   "metadata": {},
   "source": [
    "### Step 2: Estimate the fuzzy score between the input term and the HPO term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d5ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "\n",
    "def estimate_fuzzy_score(input_term, hpo_term):\n",
    "    \"\"\"\n",
    "    Estimate the fuzzy score between the input term and the HPO term.\n",
    "\n",
    "    Parameters:\n",
    "    input_term: str\n",
    "        The term reported in the study.\n",
    "    hpo_term: str\n",
    "        The term from the HPO database.\n",
    "    Returns:\n",
    "    fuzzy_score: float\n",
    "        The fuzzy score between the input term and the HPO term.\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(input_term, str):\n",
    "        raise ValueError(\"reported_term must be a string.\")\n",
    "    \n",
    "    best_match_fuzzy, fuzzy_score = process.extractOne(input_term, [hpo_term])\n",
    "    return fuzzy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dd618a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "input_term = \"headache\"\n",
    "hpo_term = \"Headache\"\n",
    "print(estimate_fuzzy_score(input_term, hpo_term))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724d5ea",
   "metadata": {},
   "source": [
    "### Step 3: Look up HPO synonyms and definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc8925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import obonet\n",
    "# def get_hpo_definitions_and_synonyms(hpo_id):\n",
    "#     \"\"\"\n",
    "#     Get the definition and synonyms for a given HPO term ID.\n",
    "#     \"\"\"\n",
    "#     url = 'http://purl.obolibrary.org/obo/hp.obo' # URL points to the Human Phenotype Ontology (HPO) in OBO format, hosted by the OBO Foundry\n",
    "#     graph = obonet.read_obo(url)\n",
    "\n",
    "#     if hpo_id in graph.nodes:\n",
    "#         synonyms = graph.nodes[hpo_id].get('synonym', []) or graph.nodes[hpo_id].get('synonyms', [])\n",
    "#         definition = graph.nodes[hpo_id].get('def', 'NA')\n",
    "#         return synonyms, definition\n",
    "#     else:\n",
    "#         return None, None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ae2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Shared ontology loader (already in your notebook) ---\n",
    "import obonet\n",
    "from functools import lru_cache\n",
    "\n",
    "HPO_URL = \"http://purl.obolibrary.org/obo/hp.obo\"\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def load_graph():\n",
    "    \"\"\"Load and cache the HPO graph once per session.\"\"\"\n",
    "    return obonet.read_obo(HPO_URL)\n",
    "\n",
    "\n",
    "# --- Improved: fast, cached meta lookup ---\n",
    "@lru_cache(maxsize=8192)  # cache per-HPO-ID lookups, too\n",
    "def get_hpo_definitions_and_synonyms(hpo_id: str):\n",
    "    \"\"\"\n",
    "    Return (synonyms, definition) for an HPO ID using the cached graph.\n",
    "    - Avoids repeated obo downloads/parsing.\n",
    "    - Cleans OBO-quoted strings for readability.\n",
    "    \"\"\"\n",
    "    graph = load_graph()  # <-- reuse cached graph\n",
    "    node = graph.nodes.get(hpo_id)\n",
    "    if not node:\n",
    "        return [], None\n",
    "\n",
    "    # Synonyms: in OBO it’s usually 'synonym' (singular); keep a fallback.\n",
    "    raw_syn = node.get(\"synonym\", []) or node.get(\"synonyms\", [])\n",
    "\n",
    "    def _clean_obo_text(s: str) -> str:\n",
    "        # OBO annotation format often looks like:  \"\\\"text\\\" EXACT [XREF:...]\"\"\n",
    "        if isinstance(s, str) and '\"' in s:\n",
    "            try:\n",
    "                return s.split('\"', 2)[1]\n",
    "            except Exception:\n",
    "                return s\n",
    "        return s\n",
    "\n",
    "    synonyms = [_clean_obo_text(s) for s in raw_syn]\n",
    "\n",
    "    # Definition may be a single string like \"\\\"text\\\" [PMID:...]\"\"\n",
    "    raw_def = node.get(\"def\")\n",
    "    definition = _clean_obo_text(raw_def) if isinstance(raw_def, str) else None\n",
    "\n",
    "    return synonyms, definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "144c83aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: ['Headache', 'Headaches']\n",
      "Definition: Cephalgia, or pain sensed in various parts of the head, not confined to the area of distribution of any nerve.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "hpo_id = \"HP:0002315\"\n",
    "synonyms, definition = get_hpo_definitions_and_synonyms(hpo_id)\n",
    "print(f\"Synonyms: {synonyms}\")\n",
    "print(f\"Definition: {definition}\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2683c",
   "metadata": {},
   "source": [
    "### Step 4: Get full lineage for a given HPO ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65b3c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obonet\n",
    "from functools import lru_cache\n",
    "\n",
    "HPO_URL = \"http://purl.obolibrary.org/obo/hp.obo\"\n",
    "\n",
    "# Cache the graph so it loads only once\n",
    "@lru_cache(maxsize=1)\n",
    "def load_graph():\n",
    "    return obonet.read_obo(HPO_URL)\n",
    "\n",
    "def get_rank_and_path(hpo_id):\n",
    "    \"\"\"\n",
    "    Return rank and path from root to this term (shortest path).\n",
    "    \"\"\"\n",
    "    graph = load_graph()\n",
    "    if hpo_id not in graph:\n",
    "        return None, []\n",
    "\n",
    "    path = [hpo_id]\n",
    "    depth = 0\n",
    "    current = hpo_id\n",
    "    while True:\n",
    "        parents = graph.nodes[current].get(\"is_a\", [])\n",
    "        if not parents:\n",
    "            break\n",
    "        current = parents[0]  # take first parent if multiple\n",
    "        path.append(current)\n",
    "        depth += 1\n",
    "        if current == \"HP:0000001\":\n",
    "            break\n",
    "    return depth, list(reversed(path)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b8e8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 4\n",
      "Lineage: ['HP:0000001', 'HP:0000118', 'HP:0000707', 'HP:0012638', 'HP:0002315']\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "hpo_id = \"HP:0002315\"\n",
    "rank, lineage = get_rank_and_path(hpo_id)\n",
    "print(f\"Rank: {rank}\")\n",
    "print(f\"Lineage: {lineage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d739c0",
   "metadata": {},
   "source": [
    "## Pipeline function to chain step 1-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a5a26b",
   "metadata": {},
   "source": [
    "Add a small normalizer and synonym-match helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77a2ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple, Optional\n",
    "try:\n",
    "    # Prefer RapidFuzz (faster, no GPL issues)\n",
    "    from rapidfuzz import fuzz, process as rf_process\n",
    "    _USE_RF = True\n",
    "except Exception:\n",
    "    # Fall back to fuzzywuzzy if RapidFuzz isn’t available\n",
    "    from fuzzywuzzy import fuzz, process as fw_process\n",
    "    _USE_RF = False\n",
    "\n",
    "def _norm(s: Optional[str]) -> str:\n",
    "    return (s or \"\").strip().lower()\n",
    "\n",
    "def synonym_matches_input(\n",
    "    input_symptom: str,\n",
    "    synonyms: Iterable[str],\n",
    "    exact: bool = True,\n",
    "    fuzzy_threshold: int = 90\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Return True if the input symptom matches any synonym (exact case-insensitive\n",
    "    or fuzzy >= threshold).\n",
    "    \"\"\"\n",
    "    inp = _norm(input_symptom)\n",
    "    syns = [_norm(s) for s in (synonyms or []) if s]\n",
    "\n",
    "    # Exact (case-insensitive)\n",
    "    if exact and inp in syns:\n",
    "        return True\n",
    "\n",
    "    # Fuzzy fallback if desired\n",
    "    if fuzzy_threshold is not None and len(syns) > 0:\n",
    "        if _USE_RF:\n",
    "            # RapidFuzz: compute max similarity quickly\n",
    "            # (rf_process.extractOne returns (match, score, idx))\n",
    "            _, score, _ = rf_process.extractOne(inp, syns, scorer=fuzz.ratio)\n",
    "            return score >= fuzzy_threshold\n",
    "        else:\n",
    "            # FuzzyWuzzy fallback\n",
    "            best, score = fw_process.extractOne(inp, syns)\n",
    "            return score >= fuzzy_threshold\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_symptoms_to_hpo_pipeline(symptom):\n",
    "    \"\"\"\n",
    "    Map reported symptoms to HPO terms and get synonyms and definitions.\n",
    "\n",
    "    Parameters:\n",
    "    symptom: str\n",
    "        The term reported in the study.\n",
    "\n",
    "    Returns:\n",
    "    hpo_term: str or None\n",
    "        The term from the HPO database.\n",
    "    hpo_id: str or None\n",
    "        The ID of the term from the HPO database.\n",
    "    fuzzy_score: float\n",
    "        The fuzzy score between the input term and the HPO term (0 if no match).\n",
    "    definition: str or None\n",
    "        The definition of the HPO term.\n",
    "    rank: int or None\n",
    "        The rank (depth) of the HPO term in the ontology.\n",
    "    path: list of str\n",
    "        The list of HPO IDs representing the path from the root to this term.\n",
    "    status: str\n",
    "        The status of the mapping ('matched' or 'not matched').\n",
    "    \"\"\"\n",
    "    # Step 1: Map reported symptoms to HPO terms\n",
    "    hpo_term, hpo_id = map_symptoms_to_hpo(symptom)\n",
    "\n",
    "    # If no match found, return immediately\n",
    "    if hpo_term is None or hpo_id is None:\n",
    "        return symptom, None, None, None, None, [], 0, 'not matched'\n",
    "\n",
    "    # Step 2: Estimate fuzzy score\n",
    "    fuzzy_score = estimate_fuzzy_score(symptom, hpo_term)\n",
    "\n",
    "    # Step 3: Get HPO definitions and synonyms\n",
    "    synonyms, definition = get_hpo_definitions_and_synonyms(hpo_id)\n",
    "    \n",
    "    # Step 4: Get full lineage\n",
    "    rank, path = get_rank_and_path(hpo_id)\n",
    "    # print(f\"Rank: {rank}, Path: {path}\")\n",
    "\n",
    "\n",
    "    # ---- Fixed acceptance rule (compare INPUT to SYNONYMS) ----\n",
    "    syn_match = synonym_matches_input(symptom, synonyms, exact=True, fuzzy_threshold=90)\n",
    "    accept = (fuzzy_score >= 80) or syn_match\n",
    "    status = 'matched' if accept else 'not matched'\n",
    "\n",
    "    return symptom, hpo_term, hpo_id, definition, rank, path, fuzzy_score, status\n",
    "\n",
    "    # # Step 5: Check if match is acceptable\n",
    "    # if fuzzy_score >= 80 or (symptom.lower() in [s.lower() for s in synonyms]):\n",
    "    #     return symptom, hpo_term, hpo_id, definition, synonyms, rank, path, fuzzy_score, 'matched'\n",
    "    # else:\n",
    "    #     return symptom, hpo_term, hpo_id, definition, synonyms, rank, path, fuzzy_score, 'not matched'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0ba8886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('headache', 'Headache', 'HP:0002315', 'Cephalgia, or pain sensed in various parts of the head, not confined to the area of distribution of any nerve.', 4, ['HP:0000001', 'HP:0000118', 'HP:0000707', 'HP:0012638', 'HP:0002315'], 100, 'matched')\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "result = map_symptoms_to_hpo_pipeline(\"headache\")\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
